{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacinthes/slovene-nli-benchmark/blob/main/GPT3.5%20synthetic%20data%20generation/synthetic_data_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Synthetic data generation**\n",
        "This is the script used to generate labeled premise hypothesis pairs.\n",
        "The script is provided with sentences, which will be used as premises and the prompt, which instructs GPT3 to generate 3 hypotheses - one for each NLI label (entailment, neutral, contradiction)"
      ],
      "metadata": {
        "id": "p9DjHQh5PGUB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvmr-GFcNlT2"
      },
      "outputs": [],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c1CDmd6nNxMw"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import re\n",
        "from time import time, sleep\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\n",
        "openai.api_key = '' # Provide your OpenAI API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ouahD_G7N4vv"
      },
      "outputs": [],
      "source": [
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "# This is the call to GPT3.\n",
        "def gpt3_completion(prompt, engine='text-davinci-003', temp=0.05, top_p=1.0, tokens=1000,\n",
        "                    freq_pen=0.0, pres_pen=0.0):\n",
        "    \n",
        "    prompt = prompt.encode(encoding='utf-8', errors='ignore').decode()\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            engine=engine,\n",
        "            prompt=prompt,\n",
        "            temperature=temp,\n",
        "            max_tokens=tokens,\n",
        "            top_p=top_p,\n",
        "            frequency_penalty=freq_pen,\n",
        "            presence_penalty=pres_pen)\n",
        "        text = response['choices'][0]['text'].strip()\n",
        "        text = re.sub('\\s+', ' ', text)\n",
        "        filename = '%s_gpt3.txt' % time()\n",
        "        \n",
        "        # Create the logs folder if it does not exists\n",
        "        if not os.path.exists('gpt3_logs'):\n",
        "            os.makedirs('gpt3_logs')\n",
        "\n",
        "        # Save the whole prompt and the response so that we can inspect it when necessary\n",
        "        with open('gpt3_logs/%s' % filename, 'w') as outfile:\n",
        "            outfile.write('PROMPT:\\n\\n' + prompt + '\\n\\n###############\\n\\nRESPONSE:\\n\\n' + text)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print('Error communicating with OpenAI:', e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read input sentences - one sentence per line\n",
        "with open(\"sample_sentences.txt\", \"r\") as f:\n",
        "    sentences = f.readlines()\n",
        "\n",
        "# strip the newline characters from the sentences\n",
        "sentences = [sentence.strip() for sentence in sentences]\n",
        "\n",
        "premises = list()\n",
        "hypotheses = list()\n",
        "labels = list()\n",
        "\n",
        "# Base prompt which instructs GPT to generate three training samples and returns them using a defined format so that it can then be parsed\n",
        "prompt_base = open_file('NLI_generation_prompt.txt')\n",
        "for sentence in tqdm(sentences):\n",
        "\n",
        "  prompt = prompt_base.replace('<<PREMISE>>', sentence) # Replace the premise with the new sentence\n",
        "  gpt3_response = gpt3_completion(prompt)\n",
        "  try:\n",
        "    # Parse and save the response\n",
        "    contradiction = re.search(r'Contradiction: (.*?) Entailment', gpt3_response).group(1)\n",
        "    entailment = re.search(r'Entailment: (.*?) Neutral', gpt3_response).group(1)\n",
        "    neutral = gpt3_response.split('Neutral: ')[1]\n",
        "\n",
        "    premises.append(sentence)\n",
        "    hypotheses.append(entailment)\n",
        "    labels.append('entailment')\n",
        "    \n",
        "    premises.append(sentence)\n",
        "    hypotheses.append(contradiction)\n",
        "    labels.append('contradiction')\n",
        "    \n",
        "    premises.append(sentence)\n",
        "    hypotheses.append(neutral)\n",
        "    labels.append('neutral')\n",
        "  except Exception as e:\n",
        "    print('Error parsing the response:', e)\n",
        "    print(f'Bad response for sentence: {sentence}')\n",
        "    print(f'Response: {gpt3_response}\\n')"
      ],
      "metadata": {
        "id": "Yuds4sTHGZLm"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXQPIRNDy3vt"
      },
      "outputs": [],
      "source": [
        "# Store the generated data locally\n",
        "df = pd.DataFrame()\n",
        "df['PREMISES'] = premises\n",
        "df['HYPOTHESES'] = hypotheses\n",
        "df['LABELS'] = labels\n",
        "df.to_excel('synthetic_data.xlsx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5+1Cd+O4UUK0RAieMMLwi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}